{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b290704",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc8e43eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "249e2364",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:\\\\Users\\\\admin\\\\OneDrive\\\\Documents\\\\Data Sciesnce Repository\\\\NLP_Application\\\\Input\\\\chatgpt_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e613d5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_extracted</th>\n",
       "      <th>text</th>\n",
       "      <th>lang</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_username</th>\n",
       "      <th>user_location</th>\n",
       "      <th>user_description</th>\n",
       "      <th>user_created</th>\n",
       "      <th>user_followers_count</th>\n",
       "      <th>user_following_count</th>\n",
       "      <th>user_tweet_count</th>\n",
       "      <th>user_verified</th>\n",
       "      <th>source</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>like_count</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>impression_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.64E+18</td>\n",
       "      <td>2023-04-03 13:59:44+00:00</td>\n",
       "      <td>07:02.5</td>\n",
       "      <td>RT @jexep: ‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡∏ù‡∏∂‡∏Å‡∏†‡∏≤‡∏©‡∏≤‡∏Å‡∏±‡∏ö ChatGPT ‡∏ó‡∏µ‡πà‡∏ú‡∏°‡∏•‡∏≠‡∏á (...</td>\n",
       "      <td>th</td>\n",
       "      <td>4706577259</td>\n",
       "      <td>üë∑üèº ‚ô° #GOT7</td>\n",
       "      <td>BPawarisa1a</td>\n",
       "      <td>‡πÉ‡∏ô‡πÉ‡∏àJacksonwang</td>\n",
       "      <td>@JacksonWang852 ‚ûñ ‡∏£‡∏µ‡∏ß‡∏¥‡∏ß #‡∏£‡∏µ‡∏ß‡∏¥‡∏ß‡πÅ‡∏ö‡∏°‡∏û‡∏µ #‡πÅ‡∏ö‡∏°‡∏û‡∏µ‡∏≠‡∏±‡∏û‡πÄ...</td>\n",
       "      <td>2016-01-04 02:27:33+00:00</td>\n",
       "      <td>1293.0</td>\n",
       "      <td>445.0</td>\n",
       "      <td>87051.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13640.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.64E+18</td>\n",
       "      <td>2023-04-03 10:59:22+00:00</td>\n",
       "      <td>06:59.4</td>\n",
       "      <td>ChatGPT„Çí„ÇÇ„Å£„Å®Ê¥ª„Åã„Åõ„ÇãChromeÊã°ÂºµÊ©üËÉΩ4ÈÅ∏ https://t.co/hfacF...</td>\n",
       "      <td>ja</td>\n",
       "      <td>2264288640</td>\n",
       "      <td>„Éü„Éü„Ç∫„ÇØ„Çä„Çì„ÇÜ</td>\n",
       "      <td>DRVO_Project</td>\n",
       "      <td>Êù±‰∫¨‚ÜêÂ≤êÈòú</td>\n",
       "      <td>ÊñôÁêÜÂû¢„Åß„Åô„ÄÇÔΩ≥ÔΩ™ÔΩØÔæåÔæû4Âπ¥ÁõÆ Áô∫Ë®Ä„ÅØ„Éï„Ç°„ÉÉ„Ç≠„É≥ÂÄã‰∫∫„ÅÆË¶ãËß£ TypeScript/Vue/Re...</td>\n",
       "      <td>2013-12-27 12:39:07+00:00</td>\n",
       "      <td>7878.0</td>\n",
       "      <td>4941.0</td>\n",
       "      <td>76597.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>290.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.64E+18</td>\n",
       "      <td>2023-04-03 03:59:28+00:00</td>\n",
       "      <td>06:52.5</td>\n",
       "      <td>RT @DarrellLerner: ChatGPT Plugins are the fas...</td>\n",
       "      <td>en</td>\n",
       "      <td>2383245894</td>\n",
       "      <td>pk</td>\n",
       "      <td>pradeep42329225</td>\n",
       "      <td>India</td>\n",
       "      <td>üíêüíê‡•§‡•§‡§ú‡§Ø ‡§∂‡•ç‡§∞‡•Ä ‡§Æ‡§π‡§æ‡§ï‡§æ‡§≤‡•§‡•§üíêüíê</td>\n",
       "      <td>2014-03-11 06:04:10+00:00</td>\n",
       "      <td>269.0</td>\n",
       "      <td>4141.0</td>\n",
       "      <td>3816.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>628.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.64E+18</td>\n",
       "      <td>2023-04-03 15:59:59+00:00</td>\n",
       "      <td>07:04.7</td>\n",
       "      <td>Get an intelligent chatbot for your website in...</td>\n",
       "      <td>en</td>\n",
       "      <td>1.63304E+18</td>\n",
       "      <td>AR Leyva</td>\n",
       "      <td>ArrheniusLey</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Passionate about AI and its potential to trans...</td>\n",
       "      <td>2023-03-07 09:43:36+00:00</td>\n",
       "      <td>264.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.64E+18</td>\n",
       "      <td>2023-04-03 01:59:25+00:00</td>\n",
       "      <td>06:50.6</td>\n",
       "      <td>üî•Hey Guys, #ZenithSwap has launched at just $ ...</td>\n",
       "      <td>en</td>\n",
       "      <td>1.3114E+18</td>\n",
       "      <td>Human Being üá®üá≥üá∏üá¨üáªüá≥</td>\n",
       "      <td>KiarostamiBeing</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Freedom is the Recognition of Necessity ‚Ä¢ Mark...</td>\n",
       "      <td>2020-09-30 20:32:00+00:00</td>\n",
       "      <td>447.0</td>\n",
       "      <td>419.0</td>\n",
       "      <td>12949.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_id              tweet_created tweet_extracted  \\\n",
       "0  1.64E+18  2023-04-03 13:59:44+00:00         07:02.5   \n",
       "1  1.64E+18  2023-04-03 10:59:22+00:00         06:59.4   \n",
       "2  1.64E+18  2023-04-03 03:59:28+00:00         06:52.5   \n",
       "3  1.64E+18  2023-04-03 15:59:59+00:00         07:04.7   \n",
       "4  1.64E+18  2023-04-03 01:59:25+00:00         06:50.6   \n",
       "\n",
       "                                                text lang      user_id  \\\n",
       "0  RT @jexep: ‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡∏ù‡∏∂‡∏Å‡∏†‡∏≤‡∏©‡∏≤‡∏Å‡∏±‡∏ö ChatGPT ‡∏ó‡∏µ‡πà‡∏ú‡∏°‡∏•‡∏≠‡∏á (...   th   4706577259   \n",
       "1  ChatGPT„Çí„ÇÇ„Å£„Å®Ê¥ª„Åã„Åõ„ÇãChromeÊã°ÂºµÊ©üËÉΩ4ÈÅ∏ https://t.co/hfacF...   ja   2264288640   \n",
       "2  RT @DarrellLerner: ChatGPT Plugins are the fas...   en   2383245894   \n",
       "3  Get an intelligent chatbot for your website in...   en  1.63304E+18   \n",
       "4  üî•Hey Guys, #ZenithSwap has launched at just $ ...   en   1.3114E+18   \n",
       "\n",
       "            user_name    user_username    user_location  \\\n",
       "0          üë∑üèº ‚ô° #GOT7      BPawarisa1a  ‡πÉ‡∏ô‡πÉ‡∏àJacksonwang   \n",
       "1             „Éü„Éü„Ç∫„ÇØ„Çä„Çì„ÇÜ     DRVO_Project            Êù±‰∫¨‚ÜêÂ≤êÈòú   \n",
       "2                  pk  pradeep42329225            India   \n",
       "3            AR Leyva     ArrheniusLey   United Kingdom   \n",
       "4  Human Being üá®üá≥üá∏üá¨üáªüá≥  KiarostamiBeing      Chicago, IL   \n",
       "\n",
       "                                    user_description  \\\n",
       "0  @JacksonWang852 ‚ûñ ‡∏£‡∏µ‡∏ß‡∏¥‡∏ß #‡∏£‡∏µ‡∏ß‡∏¥‡∏ß‡πÅ‡∏ö‡∏°‡∏û‡∏µ #‡πÅ‡∏ö‡∏°‡∏û‡∏µ‡∏≠‡∏±‡∏û‡πÄ...   \n",
       "1  ÊñôÁêÜÂû¢„Åß„Åô„ÄÇÔΩ≥ÔΩ™ÔΩØÔæåÔæû4Âπ¥ÁõÆ Áô∫Ë®Ä„ÅØ„Éï„Ç°„ÉÉ„Ç≠„É≥ÂÄã‰∫∫„ÅÆË¶ãËß£ TypeScript/Vue/Re...   \n",
       "2                             üíêüíê‡•§‡•§‡§ú‡§Ø ‡§∂‡•ç‡§∞‡•Ä ‡§Æ‡§π‡§æ‡§ï‡§æ‡§≤‡•§‡•§üíêüíê   \n",
       "3  Passionate about AI and its potential to trans...   \n",
       "4  Freedom is the Recognition of Necessity ‚Ä¢ Mark...   \n",
       "\n",
       "                user_created  user_followers_count  user_following_count  \\\n",
       "0  2016-01-04 02:27:33+00:00                1293.0                 445.0   \n",
       "1  2013-12-27 12:39:07+00:00                7878.0                4941.0   \n",
       "2  2014-03-11 06:04:10+00:00                 269.0                4141.0   \n",
       "3  2023-03-07 09:43:36+00:00                 264.0                  24.0   \n",
       "4  2020-09-30 20:32:00+00:00                 447.0                 419.0   \n",
       "\n",
       "   user_tweet_count user_verified  source  retweet_count  like_count  \\\n",
       "0           87051.0         False     NaN        13640.0         0.0   \n",
       "1           76597.0         False     NaN            0.0         0.0   \n",
       "2            3816.0         False     NaN          628.0         0.0   \n",
       "3             198.0         False     NaN            0.0         0.0   \n",
       "4           12949.0         False     NaN            0.0         0.0   \n",
       "\n",
       "   reply_count  impression_count  \n",
       "0          0.0               0.0  \n",
       "1          0.0             290.0  \n",
       "2          0.0               0.0  \n",
       "3          0.0              58.0  \n",
       "4          0.0               0.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2b3069d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_extracted</th>\n",
       "      <th>text</th>\n",
       "      <th>lang</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_username</th>\n",
       "      <th>user_location</th>\n",
       "      <th>user_description</th>\n",
       "      <th>user_created</th>\n",
       "      <th>user_followers_count</th>\n",
       "      <th>user_following_count</th>\n",
       "      <th>user_tweet_count</th>\n",
       "      <th>user_verified</th>\n",
       "      <th>source</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>like_count</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>impression_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32997</th>\n",
       "      <td>1653320000000000000.0</td>\n",
       "      <td>2023-05-02 08:59:02+00:00</td>\n",
       "      <td>15:49.0</td>\n",
       "      <td>RT @theecomlife: Affiliate Marketers are makin...</td>\n",
       "      <td>en</td>\n",
       "      <td>1281360000000000000.0</td>\n",
       "      <td>Stark TheKid</td>\n",
       "      <td>The_last_onee</td>\n",
       "      <td>Royaume-Uni</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-07-09 22:57:26+00:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>373.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1182.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32998</th>\n",
       "      <td>1653230000000000000.0</td>\n",
       "      <td>2023-05-02 02:59:22+00:00</td>\n",
       "      <td>15:43.3</td>\n",
       "      <td>RT @Phil_Lewis_: For half a century, ‚Äúthe Godf...</td>\n",
       "      <td>en</td>\n",
       "      <td>1628470000000000000.0</td>\n",
       "      <td>Crislin ü©∑</td>\n",
       "      <td>outwestwiddit</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Born, raised, living, working on the Westside....</td>\n",
       "      <td>2023-02-22 18:54:49+00:00</td>\n",
       "      <td>64.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1446.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>822.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32999</th>\n",
       "      <td>1653530000000000000.0</td>\n",
       "      <td>2023-05-02 22:59:50+00:00</td>\n",
       "      <td>16:05.0</td>\n",
       "      <td>ŸÖÿ≠ÿßÿ∂ÿ±ÿ© ÿ™ÿØÿ±Ÿäÿ®Ÿäÿ© ÿ®ÿπŸÜŸàÿßŸÜ : \\n\\nChatGPT and the Do...</td>\n",
       "      <td>und</td>\n",
       "      <td>1378740000000000000.0</td>\n",
       "      <td>ŸÖŸÜÿµÿ© ÿßŸÑÿ™ÿπŸÑŸÖ ÿßŸÑÿ≠ÿØŸäÿ´</td>\n",
       "      <td>Ok3go</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#Ÿäÿ≠ÿØÿ´_ÿßŸÑÿßŸÜ #ÿØŸàÿ±ÿßÿ™_ŸÖÿ¨ÿßŸÜŸäÿ©_ŸÖÿπÿ™ŸÖÿØÿ©\\n\\nüíõ‚ö´üü•üü®‚¨úüü©üü´üü™üüßüü§üíõ...</td>\n",
       "      <td>2021-04-04 15:52:22+00:00</td>\n",
       "      <td>5991.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4299.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>415.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33000</th>\n",
       "      <td>1653380000000000000.0</td>\n",
       "      <td>2023-05-02 12:59:20+00:00</td>\n",
       "      <td>15:53.9</td>\n",
       "      <td>RT @emollick: We just gave the world‚Äôs most po...</td>\n",
       "      <td>en</td>\n",
       "      <td>1198910000000000000.0</td>\n",
       "      <td>dorayaki</td>\n",
       "      <td>jkdorayaki</td>\n",
       "      <td>NaN</td>\n",
       "      <td>„Ç¢„Ç§„Ç≥„É≥„ÅØ„ÅÑ„Çâ„Åô„Å®„ÇÑ\\nÁâ©ÁêÜ„Åã„ÇâÁµ±Ë®à„ÉªÊ©üÊ¢∞Â≠¶Áøí„ÉªÈáëËûç/python„ÅßatcoderÊ∞¥/kag...</td>\n",
       "      <td>2019-11-25 10:08:08+00:00</td>\n",
       "      <td>208.0</td>\n",
       "      <td>336.0</td>\n",
       "      <td>716.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>193.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33001</th>\n",
       "      <td>1653340000000000000.0</td>\n",
       "      <td>2023-05-02 09:59:26+00:00</td>\n",
       "      <td>15:50.7</td>\n",
       "      <td>RT @YGPT_cn: ‚ö° ‰∏äÁ∫øÂÄíËÆ°Êó∂Ôºö3Â§© ‚ö°\\n\\nÁ≥ªÂ•ΩÂÆâÂÖ®Â∏¶ÔºåËÆ©Êàë‰ª¨‰∏ÄËµ∑ËøõÂÖ•‰∫∫Â∑•Êô∫ËÉΩ...</td>\n",
       "      <td>zh</td>\n",
       "      <td>717995000000000000.0</td>\n",
       "      <td>joe brindle</td>\n",
       "      <td>JoeBrindle_</td>\n",
       "      <td>Sheffield // Wiltshire</td>\n",
       "      <td>student, activist\\nWords in @independent, @big...</td>\n",
       "      <td>2016-04-07 08:38:41+00:00</td>\n",
       "      <td>3327.0</td>\n",
       "      <td>3798.0</td>\n",
       "      <td>5207.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1962.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    tweet_id              tweet_created tweet_extracted  \\\n",
       "32997  1653320000000000000.0  2023-05-02 08:59:02+00:00         15:49.0   \n",
       "32998  1653230000000000000.0  2023-05-02 02:59:22+00:00         15:43.3   \n",
       "32999  1653530000000000000.0  2023-05-02 22:59:50+00:00         16:05.0   \n",
       "33000  1653380000000000000.0  2023-05-02 12:59:20+00:00         15:53.9   \n",
       "33001  1653340000000000000.0  2023-05-02 09:59:26+00:00         15:50.7   \n",
       "\n",
       "                                                    text lang  \\\n",
       "32997  RT @theecomlife: Affiliate Marketers are makin...   en   \n",
       "32998  RT @Phil_Lewis_: For half a century, ‚Äúthe Godf...   en   \n",
       "32999  ŸÖÿ≠ÿßÿ∂ÿ±ÿ© ÿ™ÿØÿ±Ÿäÿ®Ÿäÿ© ÿ®ÿπŸÜŸàÿßŸÜ : \\n\\nChatGPT and the Do...  und   \n",
       "33000  RT @emollick: We just gave the world‚Äôs most po...   en   \n",
       "33001  RT @YGPT_cn: ‚ö° ‰∏äÁ∫øÂÄíËÆ°Êó∂Ôºö3Â§© ‚ö°\\n\\nÁ≥ªÂ•ΩÂÆâÂÖ®Â∏¶ÔºåËÆ©Êàë‰ª¨‰∏ÄËµ∑ËøõÂÖ•‰∫∫Â∑•Êô∫ËÉΩ...   zh   \n",
       "\n",
       "                     user_id           user_name  user_username  \\\n",
       "32997  1281360000000000000.0        Stark TheKid  The_last_onee   \n",
       "32998  1628470000000000000.0           Crislin ü©∑  outwestwiddit   \n",
       "32999  1378740000000000000.0  ŸÖŸÜÿµÿ© ÿßŸÑÿ™ÿπŸÑŸÖ ÿßŸÑÿ≠ÿØŸäÿ´          Ok3go   \n",
       "33000  1198910000000000000.0            dorayaki     jkdorayaki   \n",
       "33001   717995000000000000.0         joe brindle    JoeBrindle_   \n",
       "\n",
       "                 user_location  \\\n",
       "32997              Royaume-Uni   \n",
       "32998              Chicago, IL   \n",
       "32999                      NaN   \n",
       "33000                      NaN   \n",
       "33001  Sheffield // Wiltshire    \n",
       "\n",
       "                                        user_description  \\\n",
       "32997                                                NaN   \n",
       "32998  Born, raised, living, working on the Westside....   \n",
       "32999  #Ÿäÿ≠ÿØÿ´_ÿßŸÑÿßŸÜ #ÿØŸàÿ±ÿßÿ™_ŸÖÿ¨ÿßŸÜŸäÿ©_ŸÖÿπÿ™ŸÖÿØÿ©\\n\\nüíõ‚ö´üü•üü®‚¨úüü©üü´üü™üüßüü§üíõ...   \n",
       "33000  „Ç¢„Ç§„Ç≥„É≥„ÅØ„ÅÑ„Çâ„Åô„Å®„ÇÑ\\nÁâ©ÁêÜ„Åã„ÇâÁµ±Ë®à„ÉªÊ©üÊ¢∞Â≠¶Áøí„ÉªÈáëËûç/python„ÅßatcoderÊ∞¥/kag...   \n",
       "33001  student, activist\\nWords in @independent, @big...   \n",
       "\n",
       "                    user_created  user_followers_count  user_following_count  \\\n",
       "32997  2020-07-09 22:57:26+00:00                   2.0                  34.0   \n",
       "32998  2023-02-22 18:54:49+00:00                  64.0                  58.0   \n",
       "32999  2021-04-04 15:52:22+00:00                5991.0                   1.0   \n",
       "33000  2019-11-25 10:08:08+00:00                 208.0                 336.0   \n",
       "33001  2016-04-07 08:38:41+00:00                3327.0                3798.0   \n",
       "\n",
       "       user_tweet_count user_verified  source  retweet_count  like_count  \\\n",
       "32997             373.0         False     NaN         1182.0         0.0   \n",
       "32998            1446.0         False     NaN          822.0         0.0   \n",
       "32999            4299.0         False     NaN            1.0         0.0   \n",
       "33000             716.0         False     NaN          193.0         0.0   \n",
       "33001            5207.0         False     NaN         1962.0         0.0   \n",
       "\n",
       "       reply_count  impression_count  \n",
       "32997          0.0               0.0  \n",
       "32998          0.0               0.0  \n",
       "32999          0.0             415.0  \n",
       "33000          0.0               0.0  \n",
       "33001          0.0               0.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3a7e2c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33002, 20)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f9d6576",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet_id                    0\n",
       "tweet_created               0\n",
       "tweet_extracted             0\n",
       "text                        0\n",
       "lang                        0\n",
       "user_id                     0\n",
       "user_name                   3\n",
       "user_username               0\n",
       "user_location           13402\n",
       "user_description         5108\n",
       "user_created                4\n",
       "user_followers_count        6\n",
       "user_following_count        6\n",
       "user_tweet_count            6\n",
       "user_verified               6\n",
       "source                  33002\n",
       "retweet_count               6\n",
       "like_count                  6\n",
       "reply_count                 6\n",
       "impression_count            6\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "971c4fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['user_location', 'user_description', 'source'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad682bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1924402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet_id                0\n",
       "tweet_created           0\n",
       "tweet_extracted         0\n",
       "text                    0\n",
       "lang                    0\n",
       "user_id                 0\n",
       "user_name               0\n",
       "user_username           0\n",
       "user_created            0\n",
       "user_followers_count    0\n",
       "user_following_count    0\n",
       "user_tweet_count        0\n",
       "user_verified           0\n",
       "retweet_count           0\n",
       "like_count              0\n",
       "reply_count             0\n",
       "impression_count        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ae53988",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet_id                  493\n",
       "tweet_created           22191\n",
       "tweet_extracted           787\n",
       "text                    19511\n",
       "lang                       54\n",
       "user_id                 27614\n",
       "user_name               28586\n",
       "user_username           29141\n",
       "user_created            29122\n",
       "user_followers_count     5772\n",
       "user_following_count     4801\n",
       "user_tweet_count        19339\n",
       "user_verified               2\n",
       "retweet_count            1934\n",
       "like_count                178\n",
       "reply_count                54\n",
       "impression_count         1591\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36a67251",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_cols = df.select_dtypes(include='object').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3636951",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tweet_id', 'tweet_created', 'tweet_extracted', 'text', 'lang',\n",
       "       'user_id', 'user_name', 'user_username', 'user_created',\n",
       "       'user_verified'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d4590fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = df.select_dtypes(include=['int64', 'float64']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac8abd7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['user_followers_count', 'user_following_count', 'user_tweet_count',\n",
       "       'retweet_count', 'like_count', 'reply_count', 'impression_count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0a13ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec0c551",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from tqdm.notebook import tqdm\n",
    "from datetime import datetime\n",
    "import dateutil.parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a126b607",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e258a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud, ImageColorGenerator\n",
    "from nltk.corpus import stopwords\n",
    "import random \n",
    "from spellchecker import SpellChecker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c34fac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('vader_lexicon')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb15dcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.copy()\n",
    "data['original_tweet'] = df['text']\n",
    "data['datetime'] = data['tweet_created']\n",
    "data['datetime'] = data.datetime.apply(lambda x: dateutil.parser.parse(x))\n",
    "rt_mask = data.text.apply(lambda x: \"RT @\" in x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ab2a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.text = data.text.str.lower()\n",
    "data.text = data.text.apply(lambda x:re.sub('@[^\\s]+','',x))\n",
    "data.text = data.text.apply(lambda x:re.sub(r'\\B#\\S+','',x))\n",
    "data.text = data.text.apply(lambda x:re.sub(r\"http\\S+\", \"\", x))\n",
    "data.text = data.text.apply(lambda x:' '.join(re.findall(r'\\w+', x)))\n",
    "data.text = data.text.apply(lambda x:re.sub(r'\\s+[a-zA-Z]\\s+', '', x))\n",
    "data.text = data.text.apply(lambda x:re.sub(r'\\s+', ' ', x, flags=re.I))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef829a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['datetime'] = pd.to_datetime(data['datetime']).dt.tz_localize(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d845a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0834205b",
   "metadata": {},
   "outputs": [],
   "source": [
    "spell = SpellChecker() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd97c948",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_sentiment(x:float):\n",
    "    if x < -0.05 : return 'negative'\n",
    "    if x > 0.35 : return 'positive'\n",
    "    return 'neutral'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086f8134",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['words'] = data.text.apply(lambda x:re.findall(r'\\w+', x ))\n",
    "data['errors'] = data.words.apply(spell.unknown)\n",
    "data['errors_count'] = data.errors.apply(len)\n",
    "data['words_count'] = data.words.apply(len)\n",
    "data['sentence_length'] = data.text.apply(len)\n",
    "data['hour'] = data.datetime.apply(lambda x: x.hour)\n",
    "data['date'] = data.datetime.apply(lambda x: x.date())\n",
    "data['month'] = data.datetime.apply(lambda x: x.month)\n",
    "data['year'] = data.datetime.apply(lambda x: x.year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902ecbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "sia = SIA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9838abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['sentiment'] = [sia.polarity_scores(x)['compound'] for x in data['text']]\n",
    "data['overall_sentiment'] = data['sentiment'].apply(label_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c08487c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a17d583",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['overall_sentiment'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8c3541",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['overall_sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8f222e",
   "metadata": {},
   "outputs": [],
   "source": [
    "value_counts = data['overall_sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc04cb30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa74f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_fig.update_layout(\n",
    "    title='Overall Sentiment Value Counts (Bar Plot)',\n",
    "    xaxis_title='Sentiment',\n",
    "    yaxis_title='Count'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b2b064",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e00808",
   "metadata": {},
   "outputs": [],
   "source": [
    "pie_fig.update_layout(\n",
    "    title='Overall Sentiment Value Counts (Pie Plot)'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e500d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "data['overall_sentiment_code'] = encoder.fit_transform(data['overall_sentiment'])\n",
    "\n",
    "# Group the data by hour and overall sentiment, and calculate the count for each group\n",
    "hourly_sentiment_counts = data.groupby(['hour', 'overall_sentiment']).size().unstack()\n",
    "\n",
    "# Create a bar plot for each label\n",
    "colors = ['skyblue', 'orange', 'green']  # Specify colors for each label\n",
    "labels = hourly_sentiment_counts.columns\n",
    "x = hourly_sentiment_counts.index\n",
    "\n",
    "# Plot the bars for each label\n",
    "for i, label in enumerate(labels):\n",
    "    y = hourly_sentiment_counts[label]\n",
    "    plt.bar(x, y, color=colors[i], label=label)\n",
    "\n",
    "# Set the plot title, legend, and axis labels\n",
    "plt.title('Hourly Overall Sentiment of Tweets')\n",
    "plt.xlabel('Hour')\n",
    "plt.ylabel('Count')\n",
    "plt.legend()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a127e5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['overall_sentiment_code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971788dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0730553",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower() \n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f85b537",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new['text'] = df_new['text'].apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314e5c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c18196",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    punctuationfree=\"\".join([i for i in text if i not in string.punctuation])\n",
    "    return punctuationfree\n",
    "df_new['text']= df_new['text'].apply(lambda x:remove_punctuation(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5126e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def tokenization(text):\n",
    "    tokens = re.split('W+',text)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c45e01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new['text']= df_new['text'].apply(lambda x: tokenization(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315499a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3d0a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    output= \" \".join(i for i in text if i not in stopwords)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc30bc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new['text']= df_new['text'].apply(lambda x:remove_stopwords(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d596e165",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65197408",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatizer(text):\n",
    "    lemm_text = \"\".join([wordnet_lemmatizer.lemmatize(word) for word in text])\n",
    "    return lemm_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851eb176",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new['text']=df_new['text'].apply(lambda x:lemmatizer(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6c1e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = re.sub('\\[.*\\]','', text).strip() # Remove text in square brackets\n",
    "    text = re.sub('\\S*\\d\\S*\\s*','', text).strip()  # Remove words containing numbers\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48b8396",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new['text'] = df_new['text'].apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25219804",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_urls(vTEXT):\n",
    "    vTEXT = re.sub(r'(https|http)?:\\/\\/(\\w|\\.|\\/|\\?|\\=|\\&|\\%)*\\b', '', vTEXT, flags=re.MULTILINE)\n",
    "    return(vTEXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8516e8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new['text'] = df_new['text'].apply(lambda x: remove_urls(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983cd4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_digits(text):\n",
    "    clean_text = re.sub(r\"\\b[0-9]+\\b\\s*\", \"\", text)\n",
    "    return(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0906b296",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new['text'] = df_new['text'].apply(lambda x: remove_digits(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a14bc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_emojis(data):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    return re.sub(emoji_pattern, '', data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0cfdea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new['text'] = df_new['text'].apply(lambda x: remove_emojis(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809e2e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new['text'] = df_new['text'].apply(lambda x: re.sub(r'\\brt\\b', '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a6535e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c93160",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_data = df_new[df_new['lang'] == 'en']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867a6c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "\n",
    "# Concatenate all the text data into a single string\n",
    "text_data = ' '.join(en_data['text'])\n",
    "\n",
    "# Generate the word cloud\n",
    "wordcloud = WordCloud(background_color='white').generate(text_data)\n",
    "\n",
    "# Create a figure and axes\n",
    "fig, ax = plt.subplots(figsize=(30, 10))\n",
    "\n",
    "# Display the word cloud\n",
    "ax.imshow(wordcloud, interpolation='bilinear')\n",
    "ax.set_axis_off()\n",
    "\n",
    "# Set the plot title\n",
    "ax.set_title('Word Cloud of Sentiments')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf057085",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b3549e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all the text data into a single string\n",
    "text_data = ' '.join(en_data['text'])\n",
    "\n",
    "# Generate the word cloud\n",
    "wordcloud = WordCloud(background_color='white').generate(text_data)\n",
    "\n",
    "# Get the top ten words by frequency\n",
    "top_words = dict(sorted(wordcloud.words_.items(), key=lambda x: x[1], reverse=True)[:10])\n",
    "\n",
    "# Create a bar plot using Plotly\n",
    "fig = px.bar(\n",
    "    x=list(top_words.values()),\n",
    "    y=list(top_words.keys()),\n",
    "    orientation='h',\n",
    "    labels={'x': 'Frequency', 'y': 'Word'},\n",
    ")\n",
    "\n",
    "# Set the plot title\n",
    "fig.update_layout(title='Top 10 Words in Word Cloud')\n",
    "\n",
    "# Display the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ce6140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the text data for positive sentiment\n",
    "positive_text_data = ' '.join(en_data[en_data['overall_sentiment'] == 'positive']['text'])\n",
    "\n",
    "# Generate the word cloud for positive sentiment\n",
    "wordcloud = WordCloud(background_color='white').generate(positive_text_data)\n",
    "\n",
    "# Create a figure and axes\n",
    "fig, ax = plt.subplots(figsize=(30, 10))\n",
    "\n",
    "# Display the word cloud\n",
    "ax.imshow(wordcloud, interpolation='bilinear')\n",
    "ax.set_axis_off()\n",
    "\n",
    "# Set the plot title\n",
    "ax.set_title('Word Cloud of Positive Sentiment')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73449f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c20618e",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927120f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc9d1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = en_data[['text', 'overall_sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb8c4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ebf4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d70183",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['text'] =  df1['text'].apply(lambda x: lemmatizer(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d388c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93ae554",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.drop(index=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766045bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fd40d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(df1['overall_sentiment'])\n",
    "\n",
    "df1['overall_sentiment'] = le.transform(df1['overall_sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6aed0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792dfbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df1['text']\n",
    "y = df1['overall_sentiment']\n",
    "\n",
    "print(len(x), len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8399e078",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, shuffle = True, stratify = df1['overall_sentiment'], \n",
    "                                                    random_state=42)\n",
    "print(len(x_train), len(y_train))\n",
    "print(len(x_test), len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e36dfc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vect = CountVectorizer()\n",
    "vect.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052b6434",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_dtm = vect.transform(x_train)\n",
    "x_test_dtm = vect.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419bbd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_tunned = CountVectorizer(stop_words='english', ngram_range=(1,2), min_df=0.1, max_df=0.7, max_features=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab2a6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "\n",
    "tfidf_transformer.fit(x_train_dtm)\n",
    "x_train_tfidf = tfidf_transformer.transform(x_train_dtm)\n",
    "\n",
    "x_train_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d3d12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df1['text']\n",
    "target = df1['overall_sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5775ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e354806e",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tokenizer = Tokenizer()\n",
    "word_tokenizer.fit_on_texts(texts)\n",
    "\n",
    "vocab_length = len(word_tokenizer.word_index) + 1\n",
    "vocab_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6c2ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13725086",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed(corpus): \n",
    "    return word_tokenizer.texts_to_sequences(corpus)\n",
    "\n",
    "longest_train = max(texts, key=lambda sentence: len(word_tokenize(sentence)))\n",
    "length_long_sentence = len(word_tokenize(longest_train))\n",
    "\n",
    "train_padded_sentences = pad_sequences(\n",
    "    embed(texts), \n",
    "    length_long_sentence, \n",
    "    padding='post'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7690b4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_padded_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5325bd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()\n",
    "nb.fit(x_train_dtm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc098c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_class = nb.predict(x_test_dtm)\n",
    "y_pred_prob = nb.predict_proba(x_test_dtm)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5e4274",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957ad67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipe = Pipeline([('bow', CountVectorizer()), \n",
    "                 ('tfid', TfidfTransformer()),  \n",
    "                 ('model', MultinomialNB())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0eb63aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(x_train, y_train)\n",
    "\n",
    "y_pred_class = pipe.predict(x_test)\n",
    "\n",
    "print(metrics.accuracy_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1824678",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('bow', CountVectorizer()), \n",
    "    ('tfid', TfidfTransformer()),  \n",
    "    ('model', xgb.XGBClassifier(\n",
    "        learning_rate=0.1,\n",
    "        max_depth=7,\n",
    "        n_estimators=80,\n",
    "        use_label_encoder=False,\n",
    "        eval_metric='auc',\n",
    "    ))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79093c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(x_train, y_train)\n",
    "y_pred_class = pipe.predict(x_test)\n",
    "print(metrics.accuracy_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04acaf3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4790b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model and fitted CountVectorizer\n",
    "model = {'nb': nb, 'vect': vect}\n",
    "with open(\"nb_model.pkl\", \"wb\") as file:\n",
    "    pickle.dump(model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cd99a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e848f22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = {'nb': nb, 'vect': vect}\n",
    "joblib.dump(model, \"nb_model.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1791445",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2871deec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0349832",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
